{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Shape of train: \", train.shape)\n",
    "print(\"Shape of test: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concat train and test\n",
    "df = pd.concat((train, test))\n",
    "temp_df = df\n",
    "print(\"Shape of df: \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the all columns\n",
    "pd.set_option(\"display.max_columns\", 2000)\n",
    "pd.set_option(\"display.max_rows\", 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index as Id column\n",
    "df = df.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the null values using heatmap\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the percentages of null value\n",
    "null_percent = df.isnull().sum()/df.shape[0]*100\n",
    "null_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_for_drop = null_percent[null_percent > 20].keys() # if the null value % 20 or > 20 so need to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df = df.drop(col_for_drop, \"columns\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the unique value count\n",
    "for i in df.columns:\n",
    "    print(i + \"\\t\" + str(len(df[i].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique values of each column\n",
    "for i in df.columns:\n",
    "    print(\"Unique value of:>>> {} ({})\\n{}\\n\".format(i, len(df[i].unique()), df[i].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the target \n",
    "train[\"SalePrice\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distplot of target\n",
    "plt.figure(figsize=(10,8))\n",
    "bar = sns.distplot(train[\"SalePrice\"])\n",
    "bar.legend([\"Skewness: {:.2f}\".format(train['SalePrice'].skew())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap\n",
    "plt.figure(figsize=(25,25))\n",
    "ax = sns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, linewidth=2)\n",
    "\n",
    "# to fix the bug \"first and last row cut in half of heatmap plot\"\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heatmap of higly correlated features with SalePrice\n",
    "hig_corr = train.corr()\n",
    "hig_corr_features = hig_corr.index[abs(hig_corr[\"SalePrice\"]) >= 0.5]\n",
    "hig_corr_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.heatmap(train[hig_corr_features].corr(), cmap = \"coolwarm\", annot=True, linewidth=3)\n",
    "# to fix the bug \"first and last row cut in half of heatmap plot\"\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot regplot to get the nature of highly correlated data\n",
    "plt.figure(figsize=(16,9))\n",
    "for i in range(len(hig_corr_features)):\n",
    "    if i <= 9:\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        sns.regplot(data=train, x = hig_corr_features[i], y = 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_col = df.columns[df.isnull().any()]\n",
    "missing_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing value of Bsmt feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_col = ['BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFinType1',\n",
    "       'BsmtFinType2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtQual', 'BsmtUnfSF', 'TotalBsmtSF']\n",
    "bsmt_feat = df[bsmt_col]\n",
    "bsmt_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat = bsmt_feat[bsmt_feat.isnull().any(axis=1)]\n",
    "bsmt_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat_all_nan = bsmt_feat[(bsmt_feat.isnull() | bsmt_feat.isin([0])).all(1)]\n",
    "bsmt_feat_all_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat_all_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual = list(df.loc[:, df.dtypes == 'object'].columns.values)\n",
    "qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillinf the mising value in bsmt features\n",
    "for i in bsmt_col:\n",
    "    if i in qual:\n",
    "        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan, 'NA') # replace the NAN value by 'NA'\n",
    "    else:\n",
    "        bsmt_feat_all_nan[i] = bsmt_feat_all_nan[i].replace(np.nan, 0) # replace the NAN value inplace of 0\n",
    "\n",
    "bsmt_feat.update(bsmt_feat_all_nan) # update bsmt_feat df by bsmt_feat_all_nan\n",
    "df.update(bsmt_feat_all_nan) # update df by bsmt_feat_all_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat = bsmt_feat[bsmt_feat.isin([np.nan]).any(axis=1)]\n",
    "bsmt_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['BsmtFinSF2'].max())\n",
    "print(df['BsmtFinSF2'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(range(0,1526),5) # create a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice = df[(df['BsmtFinSF2'] >= 305) & (df['BsmtFinSF2'] <= 610)]\n",
    "df_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat.at[333,'BsmtFinType2'] = df_slice['BsmtFinType2'].mode()[0] # replace NAN value of BsmtFinType2 by mode of buet ((305.0, 610.0)\n",
    "bsmt_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat['BsmtExposure'] = bsmt_feat['BsmtExposure'].replace(np.nan, df[df['BsmtQual'] =='Gd']['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat['BsmtCond'] = bsmt_feat['BsmtCond'].replace(np.nan, df['BsmtCond'].mode()[0])\n",
    "bsmt_feat['BsmtQual'] = bsmt_feat['BsmtQual'].replace(np.nan, df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(bsmt_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_feat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing value of Garage feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_col = ['GarageArea', 'GarageCars', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'GarageYrBlt',]\n",
    "garage_feat = df[garage_col]\n",
    "garage_feat = garage_feat[garage_feat.isnull().any(axis=1)]\n",
    "garage_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_feat_all_nan = garage_feat[(garage_feat.isnull() | garage_feat.isin([0])).all(1)]\n",
    "garage_feat_all_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in garage_feat:\n",
    "    if i in qual:\n",
    "        garage_feat_all_nan[i] = garage_feat_all_nan[i].replace(np.nan, 'NA')\n",
    "    else:\n",
    "        garage_feat_all_nan[i] = garage_feat_all_nan[i].replace(np.nan, 0)\n",
    "        \n",
    "garage_feat.update(garage_feat_all_nan)\n",
    "df.update(garage_feat_all_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_feat = garage_feat[garage_feat.isnull().any(axis=1)]\n",
    "garage_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in garage_col:\n",
    "    garage_feat[i] = garage_feat[i].replace(np.nan, df[df['GarageType'] == 'Detchd'][i].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_feat.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(garage_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing value of remain feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\n",
    "df['Functional'] = df['Functional'].fillna(df['Functional'].mode()[0])\n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n",
    "df['Utilities'] = df['Utilities'].fillna(df['Utilities'].mode()[0])\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['MasVnrArea'].isnull() == True]['MasVnrType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['MasVnrType'] == 'None') & (df['MasVnrArea'].isnull() == True), 'MasVnrArea'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing value of LotFrontage feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotconfig = ['Corner', 'Inside', 'CulDSac', 'FR2', 'FR3']\n",
    "for i in lotconfig:\n",
    "    df['LotFrontage'] = pd.np.where((df['LotFrontage'].isnull() == True) & (df['LotConfig'] == i) , df[df['LotConfig'] == i] ['LotFrontage'].mean(), df['LotFrontage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting columns in str which have categorical nature but in int64\n",
    "feat_dtype_convert = ['MSSubClass', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "for i in feat_dtype_convert:\n",
    "    df[i] = df[i].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MoSold'].unique() # MoSold = Month of sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver in month abbrevation\n",
    "import calendar\n",
    "df['MoSold'] = df['MoSold'].apply(lambda x : calendar.month_abbr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MoSold'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quan = list(df.loc[:, df.dtypes != 'object'].columns.values)\n",
    "len(quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_feat = list(df.loc[:, df.dtypes == 'object'].columns.values)\n",
    "obj_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conver categorical code into order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "df['BsmtCond'] = df['BsmtCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure'] = df['BsmtExposure'].astype(CategoricalDtype(categories=['NA', 'Mn', 'Av', 'Gd'], ordered = True)).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType1'] = df['BsmtFinType1'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
    "df['BsmtFinType2'] = df['BsmtFinType2'].astype(CategoricalDtype(categories=['NA', 'Unf', 'LwQ', 'Rec', 'BLQ','ALQ', 'GLQ'], ordered = True)).cat.codes\n",
    "df['BsmtQual'] = df['BsmtQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['ExterQual'] = df['ExterQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['ExterCond'] = df['ExterCond'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['Functional'] = df['Functional'].astype(CategoricalDtype(categories=['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod','Min2','Min1', 'Typ'], ordered = True)).cat.codes\n",
    "df['GarageCond'] = df['GarageCond'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['GarageQual'] = df['GarageQual'].astype(CategoricalDtype(categories=['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['GarageFinish'] = df['GarageFinish'].astype(CategoricalDtype(categories=['NA', 'Unf', 'RFn', 'Fin'], ordered = True)).cat.codes\n",
    "df['HeatingQC'] = df['HeatingQC'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['KitchenQual'] = df['KitchenQual'].astype(CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered = True)).cat.codes\n",
    "df['PavedDrive'] = df['PavedDrive'].astype(CategoricalDtype(categories=['N', 'P', 'Y'], ordered = True)).cat.codes\n",
    "df['Utilities'] = df['Utilities'].astype(CategoricalDtype(categories=['ELO', 'NASeWa', 'NASeWr', 'AllPub'], ordered = True)).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Utilities'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show skewness of feature with distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_features = ['1stFlrSF',\n",
    " '2ndFlrSF',\n",
    " '3SsnPorch',\n",
    " 'BedroomAbvGr',\n",
    " 'BsmtFinSF1',\n",
    " 'BsmtFinSF2',\n",
    " 'BsmtFullBath',\n",
    " 'BsmtHalfBath',\n",
    " 'BsmtUnfSF',\n",
    " 'EnclosedPorch',\n",
    " 'Fireplaces',\n",
    " 'FullBath',\n",
    " 'GarageArea',\n",
    " 'GarageCars',\n",
    " 'GrLivArea',\n",
    " 'HalfBath',\n",
    " 'KitchenAbvGr',\n",
    " 'LotArea',\n",
    " 'LotFrontage',\n",
    " 'LowQualFinSF',\n",
    " 'MasVnrArea',\n",
    " 'MiscVal',\n",
    " 'OpenPorchSF',\n",
    " 'PoolArea',\n",
    " 'ScreenPorch',\n",
    " 'TotRmsAbvGrd',\n",
    " 'TotalBsmtSF',\n",
    " 'WoodDeckSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quan == skewed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "for i in range(len(skewed_features)):\n",
    "    if i <= 28:\n",
    "        plt.subplot(7,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        ax = sns.distplot(df[skewed_features[i]])\n",
    "        ax.legend([\"Skewness: {:.2f}\".format(df[skewed_features[i]].skew())], fontsize = 'xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease the skewnwnes of the data\n",
    "for i in skewed_features:\n",
    "    df[i] = np.log(df[i] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "for i in range(len(skewed_features)):\n",
    "    if i <= 28:\n",
    "        plt.subplot(7,4,i+1)\n",
    "        plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "        ax = sns.distplot(df[skewed_features[i]])\n",
    "        ax.legend([\"Skewness: {:.2f}\".format(df[skewed_features[i]].skew())], fontsize = 'xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SalePrice = np.log(train['SalePrice'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get object feature to conver in numeric using dummy variable\n",
    "obj_feat = list(df.loc[:,df.dtypes == 'object'].columns.values)\n",
    "len(obj_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy varaibale\n",
    "dummy_drop = []\n",
    "clean_df = df\n",
    "for i in obj_feat:\n",
    "    dummy_drop += [i + '_' + str(df[i].unique()[-1])]\n",
    "\n",
    "df = pd.get_dummies(df, columns = obj_feat)\n",
    "df = df.drop(dummy_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling dataset with robust scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(df)\n",
    "df = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = df[:train_len]\n",
    "X_test = df[train_len:]\n",
    "y_train = SalePrice\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "def test_model(model, X_train=X_train, y_train=y_train):\n",
    "    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n",
    "    r2 = make_scorer(r2_score)\n",
    "    r2_val_score = cross_val_score(model, X_train, y_train, cv=cv, scoring = r2)\n",
    "    score = [r2_val_score.mean()]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "LR = linear_model.LinearRegression()\n",
    "test_model(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "cross_validation = cross_val_score(estimator = LR, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Cross validation accuracy of LR model = \", cross_validation)\n",
    "print(\"\\nCross validation mean accuracy of LR model = \", cross_validation.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdg = linear_model.Ridge()\n",
    "test_model(rdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=1e-4)\n",
    "test_model(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Polynomial Regression to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_reg = SVR(kernel='rbf')\n",
    "test_model(svr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_reg = DecisionTreeRegressor(random_state=21)\n",
    "test_model(dt_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators = 1000, random_state=51)\n",
    "test_model(rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Bagging & boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\n",
    "br_reg = BaggingRegressor(n_estimators=1000, random_state=51)\n",
    "gbr_reg = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.1, loss='ls', random_state=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(br_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(gbr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "#xgb_reg=xgboost.XGBRegressor()\n",
    "xgb_reg = xgboost.XGBRegressor(bbooster='gbtree', random_state=51)\n",
    "test_model(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model Bulding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_reg.fit(X_train,y_train)\n",
    "y_pred = np.exp(svr_reg.predict(X_test)).round(2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test1 = pd.concat([test['Id'],pd.DataFrame(y_pred)], axis=1)\n",
    "submit_test1.columns=['Id', 'SalePrice']\n",
    "submit_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test1.to_csv('sample_submission.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "params = {'kernel': ['rbf'],\n",
    "         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "         'C': [0.1, 1, 10, 100, 1000],\n",
    "         'epsilon': [1, 0.2, 0.1, 0.01, 0.001, 0.0001]}\n",
    "rand_search = RandomizedSearchCV(svr_reg, param_distributions=params, n_jobs=-1, cv=11)\n",
    "rand_search.fit(X_train, y_train)\n",
    "rand_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_reg= SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.01, gamma=0.0001,\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "test_model(svr_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_reg.fit(X_train,y_train)\n",
    "y_pred = np.exp(svr_reg.predict(X_test)).round(2)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test3 = pd.concat([test['Id'],pd.DataFrame(y_pred)], axis=1)\n",
    "submit_test3.columns=['Id', 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test3.to_csv('sample_submission.csv', index=False)\n",
    "submit_test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2_reg=xgboost.XGBRegressor(n_estimators= 899,\n",
    " mon_child_weight= 2,\n",
    " max_depth= 4,\n",
    " learning_rate= 0.05,\n",
    " booster= 'gbtree')\n",
    "\n",
    "test_model(xgb2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2_reg.fit(X_train,y_train)\n",
    "y_pred_xgb_rs=xgb2_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(y_pred_xgb_rs).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rs = np.exp(xgb2_reg.predict(X_test)).round(2)\n",
    "xgb_rs_solution = pd.concat([test['Id'], pd.DataFrame(y_pred_xgb_rs)], axis=1)\n",
    "xgb_rs_solution.columns=['Id', 'SalePrice']\n",
    "xgb_rs_solution.to_csv('sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rs_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation Barplot\n",
    "plt.figure(figsize=(9,16))\n",
    "corr_feat_series = pd.Series.sort_values(train.corrwith(train.SalePrice))\n",
    "sns.barplot(x=corr_feat_series, y=corr_feat_series.index, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back1 = df_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back1.to_csv('df_for_feature_engineering.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(corr_feat_series.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
